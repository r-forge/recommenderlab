\documentclass[fleqn, a4paper]{article}
\usepackage{a4wide}
\usepackage[round,longnamesfirst]{natbib}
\usepackage{graphicx,keyval,thumbpdf,url}
\usepackage{hyperref}
\usepackage{Sweave}
\SweaveOpts{strip.white=TRUE}
\AtBeginDocument{\setkeys{Gin}{width=0.6\textwidth}}

%\documentclass[article]{jss}

\usepackage[utf8]{inputenc}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{amsfonts}


\newcommand{\strong}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\newcommand{\class}[1]{\mbox{\textsf{#1}}}
\newcommand{\func}[1]{\mbox{\texttt{#1()}}}
\newcommand{\code}[1]{\mbox{\texttt{#1}}}
\newcommand{\pkg}[1]{\strong{#1}}
\newcommand{\samp}[1]{`\mbox{\texttt{#1}}'}
\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\sQuote}[1]{`{#1}'}
\newcommand{\dQuote}[1]{``{#1}''}
\newcommand\R{{\mathbb{R}}}
\newcommand{\mat}[1]{{\mathbf{#1}}}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\sloppy

%% \VignetteIndexEntry{An introduction to the R package recommenderlab}

\begin{document}

\title{\pkg{recommenderlab}: Infrastructure for Testing and 
Developing Recommender Algorithms for Binary Data}
\author{Michael Hahsler}
\maketitle
\sloppy


\abstract{
   \pkg{recommenderlab} provides the infrastructure to test and develop
       recomender algorithms. Currently the focus is on recommender
           systems for binary data.
    }


<<echo=FALSE>>=
options(scipen=3, digits=4)
### for sampling
set.seed(1234)
@

\section{Introduction}

Recommender systems apply statistical and knowledge discovery techniques to the problem of making product recommendations {\small\citep{Sarwar:2000}}.

{\bf Advantages of recommender systems}~{\small\citep{Schafer:2001}}:
\begin{itemize}
\item Improve conversion rate: Help customer find a product she/he wants to buy.
\item Cross-selling: Suggest additional products.
\item Improve loyalty: By creating a value-added relationship.
\end{itemize}

{\bf Types of recommender systems}~{\small\citep{Ansari:2000}}:
\begin{itemize}
\item Content filtering: Consumer preferences for product attributes.
\item \emph{Collaborative filtering:} Mimics word-of-mouth based on analysis of
rating/usage/sales data.
\end{itemize}

{\bf Input:} Typically rating data (here 1-5 stars for movies).


{\bf Output:}
\begin{itemize}
\item
Predicted rating of unrated movies {\small\citep{Breese:1998}}
\item
A top-$N$ list of unrated (unknown) movies ordered by predicted
rating/score {\small\citep{Deshpande:2004}}
\end{itemize}

\emph{Heterogeneity of collected data}

{\bf Typical situation for many businesses:}
{\small
\begin{itemize}
\item No rating data available
\item Extremely heterogeneous data sources
\item \emph{Very limited research on recommender systems based on binary data
available.}
\end{itemize}

\section{Recommender algorithms}

Notation:

Set of users $\set{U} = \{u_1, u_2, \ldots, u_\m}$

Incomplete 0-1 $m \times n$ matrix $\mat{U}$ where the rows are user $u_i$ for $0>i>m$
and the columns are items $i_j$ for $0>j>n$. The matrix is incomplete since
it next to 0 and 1 it also contains missing values.


\subsection{User-based Collaborative Filtering (CF)}
Produce recommendations based on preferences of similar users {\small\citep{Goldberg:1992,Resnick:1994,Mild:2001}}.

\centerline{\includegraphics[scale=1]{user-based}}

\small
\begin{enumerate}
\item
Find $k$ nearest neighbors based on
similarity between users.
\item Generate recommendation based on the items liked by the $k$ nearest
neighbors. E.g., recommend most popular items or use a weighing scheme.
\end{enumerate}

Measure 
similarity between two users $u_x$ and $u_y$:
\begin{itemize}
\item \emph{Pearson correlation coefficient:}
$$\mathrm{sim_{Pearson}}(\mathbf{x},\mathbf{y}) = 
	    \frac{\sum_{i \in I} x_iy_i - I\bar{\mathbf{x}}\bar{\mathbf{y}}}
		    {(I-1)s_xs_y}$$

\item \emph{Cosine similarity:}
$$\mathrm{sim_{Cosine}}(\mathbf{x},\mathbf{y}) = 
	    \frac{\mathbf{x}\cdot\mathbf{y}}
		    {\|\mathbf{x}\|_2\|\mathbf{y}\|_2}$$
\item \emph{Jaccard index} (only binary data):

$$\mathrm{sim_{Jaccard}}(X,Y) = \frac{|X\cap Y|}{|X\cup Y|}$$ 
\end{itemize}

where
$\mathbf{x} = b_{u_x,\cdot}$ and 
$\mathbf{y} = b_{u_y,\cdot}$ represent the user's profile vectors and 
$X$ and $Y$ are the sets of the items with a 1 in the respective profile.


{\bf Problems:} Memory-based. Expensive online similarity computation.


\subsection{Item-based CF}
Produce recommendations based on item similarities~{\small\citep{Kitts:2000,Sarwar:2001}}

\centerline{\includegraphics[scale=1]{item-based2}}
\begin{enumerate}
\small
\item Calculate similarities between items and keep for each item 
only the values for 
the $k$ most similar items.

\item For each item add the similarities with the active user's items.
\item Remove the items of the active user and recommend the $N$ items 
with the highest score.
\end{enumerate}

{\bf Similarity measures:}
\begin{itemize}
\item Pearson correlation coefficient, cosine similarity, jaccard index
\item \emph{Conditional probability-based 
similarity}~{\small\citep{Deshpande:2004}}:
	$$\mathrm{sim_{Conditional}}(x,y) = 
	    \frac{\mathrm{Freq}(xy) }
		    {\mathrm{Freq}(x)} = \hat{P}(y|x)$$
where $x$ and $y$ are two items,
$\mathrm{Freq(\cdot)}$ is the number of users with the given item in their
profile.

%With normalization and reduction of the problem with rare $x$:\\[4mm]
%\centerline{
	%%\Large
	%$\mathrm{sim_{Karypis}}(x,y) = 
	%    \frac{\sum_{\forall i b_{i,x}} b_{i,y} }
	%    {\mathrm{Freq}(x) \mathrm{Freq}(y)^\alpha}$
	%}
	%where rows in $\mathbf{B} = (b_{i,j})$ are normalized to sum up to $1$, 
	%and the rows of the resulting similarity matrix are normalized to sum up to $1$ again. $\mathrm{Freq}(y)^\alpha$ reduces the problem with rare $x$.
	%
	% add more
\end{itemize}

%\section{Properties}
{\bf Properties:}
	\begin{itemize}
\item Models (reduced similarity matrix) 
	is relatively small ($N \times k$) and
	can be fully precomputed. 
	\item Item-based CF is known to 
	only produce slightly inferior results compared to user-based 
	CF~{\small\citep{Deshpande:2004}}.
	\item Higher order models 
	which take the joint distribution of
	sets of items into account 
	are possible {\small\citep{Deshpande:2004}}.
\item Successful application in large scale systems (e.g., Amazon.com)
\end{itemize}

\subsection{Association Rules}
Produce recommendations based on a dependency model for items 
given by association 
rules~{\small\citep{Fu:2000,Mobasher:2001,Geyer-Schulz:2002,Lin:2002,Demiriz:2004}} 

The binary profile matrix $\mathbf B$ is seen as a database containing 
the set of items $\mathcal{I} = \{i_1, i_2, \dots, i_I\}$. 
Each user is treated as a transaction.

{\bf Rule:} $X \rightarrow Y$  where $X, Y \subseteq \mathcal{I}$, $X \cap Y = \emptyset$ and $|Y| = 1$.

{\bf Measures of significance and interestingness:}
\begin{equation*}
\mathrm{support}(X \rightarrow Y) = \mathrm{support}(X \cup Y) = 
\mathrm{Freq}(X \cup Y) / U > s
\end{equation*}
\begin{equation*}
\mathrm{confidence}(X \rightarrow Y) = \mathrm{support}(X \cup Y) / \mathrm{support}(X) = \hat{P}(Y|X) > c 
\end{equation*}

{\bf Length constraint:}
\begin{equation*}
|X \cup Y|\leq l
\end{equation*}

\begin{enumerate}
\item Dependency model: All rules of form $X \rightarrow Y$ 
with minimum support
$s$, minimum confidence $c$ and satisfying the length constraint $l$.
\item Find all maching rules $X \rightarrow Y$ for which $X \subseteq u_a$.
\item Recommend $N$ unique right-hand-sides ($Y$) of the maching rules 
with the highest confidence.
\end{enumerate}

{\bf Properties:}
\begin{itemize}
\item Model grows in the worst case exponentially with the 
number of items. Model size can be controlled by $l$, $s$ and $c$.
\item Model is very similar to
item-based CF with conditional probability-based similarity (with higher order effects). 
basher et al [Mobasher et al. 2000] presented an algorithm for recommending
%additional webpages to be visited by a user based on association rules. In this
%approach, the historical information about users and their web-access patterns
%were mined using a frequent itemset discovery algorithm and were used to
%generate a set of high con- fidence association rules. The recommendations were
%computed as the union of the consequent of the rules that were supported by the
%pages visited by the user. Lin et al [Lin et al. 2000] used a similar approach
%but they developed an algorithm that is guaranteed to find association rules
%for all the items in the database. Finally, within the context of using
%association rules to derive top-N recommendations, Demiriz [Demiriz 2001]
%studied the problem of how to weight the different rules that are supported
%by the active user. He presented a method that computes the similarity
%between a rule and the active user¿s basket as the product of the confi-
%dence of the rule and the Euclidean distance between items in the
%antecedent of the association rule and the items in the user¿s basket. He
%compared this approach both with the item-based scheme described in Section
%4 (based on our preliminary work presented in [Karypis 2001]) and the
%dependency network-based algorithm [Hecker- man et al. 2000].


\end{itemize}






\section{Recommenderlab Infrastructure}
\section{Examples}
\subsection{A first session}

For this example we use the data set \emph{MSWeb} which is included in
\pkg{recommenderlab}. 
The data set contains anonymous web data from \url{www.microsoft.com} 
for 38,000 anonymous, randomly-selected users. For each
user, the data lists all the areas of the web site (Vroots) that user visited
in a one week time frame {\small\citep{Breese:1998}}.

{\bf Used data:}\\
$4151$ users with $>5$ items and $285$ items. \\
Avg. items per profile:~$8.16$
\marginpar{introduce data}

<<>>=
library("recommenderlab")
data(MSWeb)

MSWeb_5 <- MSWeb[size(MSWeb) >5]
MSWeb_5
@

The data is stored in sparse format as an object of \class{itemMatrix}
defined in package \pkg{arules} which holds a sparse item incidence matrix
and item information (e.g., item names).

A recommender is created using \func{recommender}.
Here we create a simple recommender which generates recommendations 
solely on the popularity of items (the number of users who have the item in
their profile).

<<>>=
r <- recommender(MSWeb_5, method = "POPULAR")
r

str(recommender_model(r))
@

The model can be obtained from a recommender using \func{recommender\_model}.
In this case the model is just an vector containing the order of items
according to popularity in the data set and a short description.

Recommendations are generated by \func{predict} in the same way \func{predict}
is used in \proglang{R} for other types of models. The result 
are recommendations in sparse format represented as an \class{itemMatrix}.
\func{inspect} (defined in \pkg{arules}) can be used to
print the recommended items.

<<>>=
recom <- predict(r, MSWeb_5[1:2], n=5)
recom
inspect(recom)
@


\subsection{Evaluation}

\pkg{recommenderlab} provides different evaluation methods. The evaluation
method is determined by choosing an evaluation scheme. Here we create
a $4$-fold cross-valiadation scheme with 3 items given.
\marginpar{explain more.}

<<>>=
es <- evaluation_scheme(MSWeb_5, method="cross", k=4, given=3)
es
@

<<>>=
conf_m <- evaluate(es, method="POPULAR", n=c(1,5,10,20))
conf_m

mean(conf_m)
@

<<fig=TRUE>>=
plot(conf_m)
@

<<fig=TRUE>>=
plot(conf_m, plot_type="prec/rec")
@

\subsection{Comparing different methods}


<<echo=FALSE>>=
load("conf_m.rda")
@

<<eval=FALSE>>=
## this needs to be saved to disk! see run_recommender.R
algorithms <- list(
        RANDOM = list(name="RANDOM", para=NULL),
        POPULAR = list(name="POPULAR", para=NULL),
        UBCF = list(name="UBCF", para=list(method="cosine", nn=50)),
        IBCF = list(name="IBCF", para=list(k=30)),
        AR = list(name="AR", para=list(supp=0.05, conf=0.5, maxlen=2))
        )

## run algorithms
conf_m <- lapply(algorithms, FUN = function(a) evaluate(es, a[["name"]], 
	n=c(1,5,10,20), parameter=a[["param"]]))

conf_m <- evaluation_list(conf_m)

## save(conf_m, file="conf_m.rda")
@

<<fig=TRUE>>=
plot(conf_m)
@

<<fig=TRUE>>=
plot(conf_m, plot_type="prec/rec")
@

\marginpar{getting data in missing!}

\subsection{Compare rankings}

Top-$N$ recommendation lists can be considered rankings
	and can be 
represented as $N$-ary order relations ($\leq$) 
	on the set of all items in the lists (items which do not occur in all lists 
			are added to the end of the corresponding order).

{\bf Average distance between methods:}
E.g., the cardinality of the symmetric difference of two relations (the
		number of tuples contained in exactly one of two relations) 
{\small\citep{Hornik:2008}}

Total number of tuples in relations: 8649 (for 93 items)

	\begin{verbatim}
	UB   IB   AR Pop N
	UB       0 2555 2634  3317
	IB    2555    0 1611  2052
	AR    2634 1611    0  2636
	Pop N 3317 2052 2636     0
	\end{verbatim}

\small
\begin{verbatim}
u_a = {Toy Story (1995), Air Force One (1997), 
	Cop Land (1997), Michael (1996), Blade Runner (1982)}

	UB IB AR Top N Consensus*
	Contact (1997)                 1  4 25     4         4
	Liar Liar (1997)               2 18 32    10         8
	Conspiracy Theory (1997)       3 NA NA    NA        NA
	Star Wars (1977)               4  1  1     1         1
	Return of the Jedi (1983)      5  2  4     2         2
	English Patient, The (1996)    6 26 41     6        12
	Saint, The (1997)              7 NA NA    NA        NA
	Fargo (1996)                   8  3 13     3         3
	Mr. Holland's Opus (1995)      9 34 30    39        17
	Scream (1996)                 10 20 35     7        10
	\end{verbatim}

	* Consensus method: Condorcet (minimizes the weighted sum 
			of symmetric difference distance)




\subsection{ROCR interface}

\subsection{Implementing a new recommender algorithm}

\section{Conclusion}

{\bf Challenges with CF and binary data:}
\begin{itemize}
\item Sparsity of data has an adverse effect on similarity calculation/neighborhood formation.
\item The meaning of $0$ in the data can be either of ``unknown'' or
``dislike''.
Measures like the Jaccard index focus on $1$s.
\item Quality of recommendations is extremely data set dependent.
\end{itemize}


{\bf Bias of evaluation method:}
\begin{itemize}
\item Complete set of ``liked'' items is unknown. Measured precision
is only a lower bound to real precision.
\end{itemize}

\begin{itemize}
\item Many companies face heterogeneous data sources which can best be
aggregated into binary data. 
\item There is only limited research on CF recommender systems using 
binary data 
(except {\small\citep{Breese:1998,Mild:2001,Mild:2003, Demiriz:2004}})
available. More research is needed.
\end{itemize}

{\bf Future research}
\begin{itemize}
\item Provide an open source research toolbox for
recommendations based on binary data with the R code used here. 
\item Model ``dislike'' in binary data {\small\citep{Mobasher:2001}}.
%\item Account for fast changing products 
%    (e.g., vintages differ often significantly and change every year).
\item Investigate recommender engines based on consensus rankings.
\end{itemize}






%
%\bibliographystyle{abbrvnat}
%\bibliography{recommenderlab}
%

\bibliographystyle{abbrvnat}
\bibliography{recom_talk,data,stuff}

\end{document}


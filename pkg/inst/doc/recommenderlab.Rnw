\documentclass[fleqn, a4paper]{article}
\usepackage{a4wide}
\usepackage[round,longnamesfirst]{natbib}
\usepackage{graphicx,keyval,thumbpdf,url}
\usepackage{hyperref}
\usepackage{Sweave}
\SweaveOpts{strip.white=TRUE}
\AtBeginDocument{\setkeys{Gin}{width=0.6\textwidth}}

%\documentclass[article]{jss}

\usepackage[utf8]{inputenc}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{amsfonts}


\newcommand{\strong}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\newcommand{\class}[1]{\mbox{\textsf{#1}}}
\newcommand{\func}[1]{\mbox{\texttt{#1()}}}
\newcommand{\code}[1]{\mbox{\texttt{#1}}}
\newcommand{\pkg}[1]{\strong{#1}}
\newcommand{\samp}[1]{`\mbox{\texttt{#1}}'}
\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\set}[1]{\mathcal{#1}}
\newcommand{\sQuote}[1]{`{#1}'}
\newcommand{\dQuote}[1]{``{#1}''}
\newcommand\R{{\mathbb{R}}}
\newcommand{\mat}[1]{{\mathbf{#1}}}
\renewcommand{\vec}[1]{{\mathbf{#1}}}

\sloppy

%% \VignetteIndexEntry{An introduction to the R package recommenderlab}

\begin{document}

\title{Developing and Tesing Top-$N$ Recommendation Algorithms
for 0-1 Data using \pkg{recommenderlab}}
\author{Michael Hahsler}
\maketitle
\sloppy


\abstract{
   \pkg{recommenderlab} provides the infrastructure to test and develop
       recomender algorithms. Currently the focus is on recommender
           systems for binary data.
    }


<<echo=FALSE>>=
options(scipen=3, digits=4)
### for sampling
set.seed(1234)
@

\section{Introduction}
Predicting ratings and creating personalized recommendations for products like
books, songs or movies online came a long way from the first system using
\emph{social filtering} created by \cite{recommender:Malone:1987} more than 20
years ago.  Today recommender systems are an accepted technology used by market
leaders in several industries (e.g., by amazon.com, iTunes and Netflix).  
Recommender
systems apply statistical and knowledge discovery techniques to the problem of
making product recommendations \citep{recommender:Sarwar:2000}.  Such
recommendations can help to improve the conversion rate by help customer find a
product she/he wants to buy faster, promote cross-selling by suggesting
additional products and can improve customer loyalty through creating a
value-added relationship~\citep{recommender:Schafer:2001}.  The importance and
the economic impact of research in this field is reflected by the Netflix prize
(\url{http://www.netflixprize.com/}), a challange to improve algorithms to
predict user ratings for movies.  A grand price of 1 million dollar was just
awarded to the winning team.

The most widely used method to create recommendations is \emph{collaborative
filtering}. The idea is that given rating data by many users for many items
(e.g., 1 to 5 stars for movies elicited directly from the users), 
one can predict a user's rating for an item
not known to her or him~\citep[see, e.g.,][]{recommender:Goldberg:1992} 
or create
for a user a so called top-$N$ lists of recommended 
items~\citep[see, e.g.,][]{Deshpande:2004}.
For these type of recommender systems, several projects were initiated to
implement recommender algorithms (e.g., Apache Mahout/Taste, Cofi, CoFE,
RACOFI, SUGGEST, Vogoo PHP).

Nearly no research~\citep[with some notable exceptions by][]{recommender:Weiss:2001,recommender:Mild:2003,recommender:Lee:2005,recommender:Pan:2008}
was done for situations where no large amount of detailed
rating data is available. However, this is a common situation and occurs when
users do not want to directly reveal their preferences by rating an item 
(e.g., because it is to time consuming). In
this case preferences can only be infered by analyzing usage behavior
For
example, we can easily record in a supermarket setting what items a customer
purchases, but we do not know if some items were not purchased because the
customer does not like them (these should not be recommended) or just does not
know about them (these maye should be recommended). The same is true for
recommending pages of a web site given click-stream data. Here we only have
information about which pages were viewed but not why some pages were not
viewed. This situation leads to
binary data or more exactly to
0-1 data where 1 means that we infered that
the user has a preference for an item and 0 means that either the user does not like the item or does not know about it. 
\cite{recommender:Pan:2008} calls
this type of data in the context of collaborative filtering
analogouse to similar situations for classifiers
\emph{one-class data} since only the 1-class is pure and contains only
possitive examples. The 0-class is a mixture of positive and negative examples.

The \proglang{R} extension package~\pkg{recommenderlab} provides a general
infrastructure for collaborative filtering.  In this paper we will focus on the
package's capabilities for creating and testing recommender algorithms which
create top-$N$ recommendation list for 0-1 data.

%A problems that recommender systems typically have to deal with are:
%sparse data and cold start problem.

%memory-based, model-based

%Evaluation


This paper is structured as follows. Section...


\section{Collaborative Filtering}

Collaborative filtering (CF) uses given rating data by many users for many
items as the basis of predicting missing ratings or create top-$N$
recommendations for a given user, called the active user.  
Formally, we have a set of 
users $\set{U} = \{u_1, u_2, \ldots, u_m\}$ and a set of 
items $\set{I} = \{i_1, i_2, \ldots, i_n\}$.
Ratings are stored in a $m \times n$ rating matrix $\mat{R} = (r_{jk})$ where
the rows represent the user $u_j$ for $1 \ge j\ge m$ and columns represent
items $i_k$ for $1 \ge k\ge n$. $r_{jk}$ represents the rating of user
$u_j$ for item $i_k$.
Typically only a small fraction of ratings are
known and for many cells in $\mat{R}$ the values are missing. Most published
algoritms operate on ratings on a scale of 1 to 5 (stars)
and estimated ratings are allowed to be in the interval $[1,5]$.
However in this
paper we concentrate on the 0-1 case with $r_{jk} \in {0,1}$ where we define:
\begin{equation}
r_{jk}=
\begin{cases}
1& \text{user $u_j$ has a preference for item $i_k$} \\
0& \text{otherwise.}
\end{cases}
\end{equation}

The aim of collaborative filtering is to create recommendations for a user
called the active user $u_a \in \set{U}$.  
We define the set of items unkown to user $u_a$ as 
$\set{I}_a = \set{I} \setminus \{i_l \in \set{I}| r_{al} = 1\}$.
The two typical tasks are to predict
ratings for the items in $\set{I}_a$ or to create a list of 
the best $N$ recommendations
(i.e., a top-$N$ recommendation list) for 
$u_a$~\citep{recommender:Sarwar:2001}. 
Creating a top-$N$ lists can
be seen as a second step after predicting ratings for all 
unknown items in $\set{I}_a$
and then taking the $N$ items with the highest predicted ratings. However,
given that there are typically many items with unknown ratings 
some apporaches (e.g., rule based approaches) can
predict directly the top-$N$ list without considering all unknown items first.

Formally, predicting all missing ratings is calculating a complete row of the
rating matrix $\hat{r}_{a\cdot}$ where the missing values 
for items in $\set{I}_a$ (zeros in the 0-1 case)
are replaced by ratings estimated from other data in $\mat{R}$.  
The estimated ratings can either be again in $\{0,1\}$ or to 
in $[0,1]$, where estimates closer to 1 indicate a stronger recommendation.
The latter type of estimation is needed to be able to create a top-$N$
list.
A list
of top-$N$ recommendations for a user $u_a$ is an partially ordered set 
$T_N = (\set{X}, \ge)$, where 
$\set{X} \subset \set{I}_a$ and
$|\set{X}| \le N$ ($|\cdot|$ denotes the cardinality of the set). 
Note that there may exist cases
where top-$N$ lists contain less than $N$ items. This can happen if 
$|\set{I}_a| < N$ or if the CF algorithm is unable to 
identify $N$ items to recommend.
The binary relation $\ge$ is defined as 
$x\ge y$ if and only if 
$\hat{r}_{ax} \ge
\hat{r}_{ay}$ for all $x,y \in \set{X}$. Furthermore we 
require that $\forall_{x\in \set{X}} \forall_{y\in \set{I}_a} \quad \hat{r}_{ax} \ge \hat{r}_{ay}$ to ensure that the top-$N$ list contains
only the items with the highest estimated rating.


Collaborative filtering algorithms are typically divided into two groups,
\emph{memory-based} and \emph{model-based} 
algorithms~\citep{recommender:Breese:1998}. Memory-based algorithms
use the whole (or at least a large sample of the) user database to create 
recommendations. The most prominent algorithm is 
user-based collaborative filtering. 
The disadvantages of this approach is scalability since the whole
user database has to be processed online for creating recommendations.
Model-based algorithms 
use the user database to learn a more compact model (e.g, clusters
with users of similar preferences) that is later used to create
recommendations.

In the following we will present well known memory and model-based
collaborative filtering algorithms and apply them to 0-1 data.

\subsection{User-based Collaborative Filtering}

User-based CF~\citep{Goldberg:1992,Resnick:1994,recommender:Shardanand:1995} is
a memory-based algorithm which tries to mimics word-of-mouth based on analysis
of rating data. The idea is that 
users with similar preferences will rate products similarly. Thus a
missing ratings for a user can be predicted by first 
finding a \emph{neighborhood} of similar users and then aggregate the 
ratings of these users to form a prediction.

The neighborhood is defined in terms of similarity between users,
either by taking a given number of most similar users ($k$ nearest neighbors) 
or all users within
a given similarity threshold.
Popular similarity measures for CF are
the \emph{Pearson correlation coefficient} and
the \emph{Cosine similarity}. These similarity measures are defined
between two users $u_x$ and $u_y$ as
$$\mathrm{sim_{Pearson}}(\vec{x},\vec{y}) = 
	    \frac{\sum_{i \in I} (\vec{x}_i \, \bar{\vec{x}})(\vec{y}_i \, \bar{\vec{y}})}
		{(|I| -1) \, \mathrm{sd}(\vec{x}) \, \mathrm{sd}(\vec{y})}
$$

and
$$\mathrm{sim_{Cosine}}(\vec{x},\vec{y}) = 
	    \frac{\vec{x}\cdot\vec{y}}
		    {\|\vec{x}\|_2\|\vec{y}\|_2},$$
where
$\vec{x} = r_{x\cdot}$ and 
$\vec{y} = r_{y\cdot}$ represent the users' profile vectors.
$\mathrm{sd}(\cdot)$ is the standard deviation.
For calculating similarity using rating data only the dimensions (items) 
are used which were rated by both users. However, for 0-1 data that would lead
to the problem that the vectors $\vec{x}$ and $\vec{y}$ only contain ones
and thus no useful measure can be calculated. 

If we assume that most zeroes are actually items that the user does not like,
we can use all items in the similarity calculation. However, this will produce
significant errors for newer users who used a few items. 
A similarity measure which
only focuses on matching ones 
and thus prevents the problem with zeroes
is the \emph{Jaccard index}:
$$\mathrm{sim_{Jaccard}}(\set{X},\set{Y}) = \frac{|\set{X}\cap \set{Y}|}
{|\set{X}\cup \set{Y}|},$$ 
where
$\set{X}$ and $\set{Y}$ are the sets of the items with a 1 in user profiles
$u_a$ and $u_b$, respectively.



\begin{figure}
\centerline{\includegraphics[scale=1]{user-based}}
\caption{User-based collaborative filtering.}
\label{fig:UBCF}
\end{figure}

\marginpar{aggregation}

An example of the process of creating recommendations for 0-1 data by
user-based CF is shown in Figure~\ref{fig:UBCF}. To the left is the rating
matrix $\mat{R}$ with 6 users and 8 items. The active user $u_a$ we want to
create recommendations for is added to the top of the matrix.  To find the
$k$-neighborhood (i.e., the $k$ nearest neighbors) we calculate the similarity
between the active user and all other users in the database and then select the
$k$ users with the highest similarity.  To the right in Figure~\ref{fig:UBCF}
we see a $2$-dimensional representation of the similaries (users with higher
similarity are closer) with the active user in the center. The $k=3$ nearest
neighbors are selected and marked in the database to the left. To generate an
aggregated score, the ones in the selected users are summed. Then items known
to the active user are removed and the $N$ items with the highest score
(greater than zero) form the top-$N$ recommendations. In the example in 
Figure~\ref{fig:UBCF} only two items are recommended.

%% default voting, case amplification (Breese, 1998)
% use a weighing scheme.
% aggregation seems to be more important

The two main problems of user-based CF are that the whole
user database has to be kept in memory and that 
expensive similarity computation between the active user and
all other users in the database has to be performed.


\subsection{Item-based CF}
Item-based CF~\citep{Kitts:2000,Sarwar:2001,recommender:Linden:2003,recommender:Deshpande:2004}
is a model-based approach which produces recommendations
by based on the relationship between items infered from the rating
matrix. The idea behind this approach is that users will prefer items that
are similar to the items they like.

The model-building step consists of calculating as similarity matrix
containing all item-to-item similarities using a given similarity measure.
Popular are again Pearson correlation and Cosine similarity. For 0-1
data again the Jaccard index can be used giving focus to matching ones.
For item-based CF \cite{Deshpande:2004} proposed
a \emph{Conditional probability-based 
similarity} defined as:
	$$\mathrm{sim_{Conditional}}(x,y) = 
	    \frac{\mathrm{Freq}(xy) }
		    {\mathrm{Freq}(x)} = \hat{P}(y|x),$$
where $x$ and $y$ are two items,
$\mathrm{Freq(\cdot)}$ is the number of users with the given items in their
profile.

\marginpar{fix this}

With normalization and reduction of the problem with rare $x$:
	$$\mathrm{sim_{Karypis}}(x,y) = 
	    \frac{\sum_{\forall i b_{i,x}} b_{i,y} }
	    {\mathrm{Freq}(x) \mathrm{Freq}(y)^\alpha}$$
	where rows in $\mathbf{B} = (b_{i,j})$ are normalized to sum up to $1$, 
	and the rows of the resulting similarity matrix are normalized to sum up to $1$ again. $\mathrm{Freq}(y)^\alpha$ reduces the problem with rare $x$.
	
To reduce the model size, for each item only a list of the $k$ most similar
items and the similarity value can be stored~\citep{Sarwar:2001} improving
space and time complexity by reducing recommendation quality.

To make a recommendation based on the model,  



\begin{enumerate}
\item For each item add the similarities with the active user's items.
\item Remove the items of the active user and recommend the $N$ items 
with the highest score.
\end{enumerate}


\begin{figure}
\centerline{\includegraphics[scale=1]{item-based2}}
\caption{Item-based collaborative filtering}
\label{fig:IBCF}
\end{figure}


%\section{Properties}
{\bf Properties:}
	\begin{itemize}
\item Models (reduced similarity matrix) 
	is relatively small ($N \times k$) and
	can be fully precomputed. 
	\item Item-based CF is known to 
	only produce slightly inferior results compared to user-based 
	CF~{\small\citep{Deshpande:2004}}.
	\item Higher order models 
	which take the joint distribution of
	sets of items into account 
	are possible {\small\citep{Deshpande:2004}}.
\item Successful application in large scale systems (e.g., Amazon.com)
\end{itemize}

\subsection{Association Rules}
Produce recommendations based on a dependency model for items 
given by association 
rules~{\small\citep{Fu:2000,Mobasher:2001,Geyer-Schulz:2002,Lin:2002,Demiriz:2004}} 

The binary profile matrix $\mat{R}$ is seen as a database containing 
the set of items $\set{I}$ and each user is treated as a transaction.
To build a model, a set of association rules \set{R} is mined from
$\mat{R}$. Association rules are rules of the form
$\set{X} \rightarrow \set{Y}$  where $\set{X}, \set{Y} \subseteq \set{I}$
and $\set{X} \cap \set{Y} = \emptyset$.
For the model we only use association rules with a single item in
the right-hand-side of the rule ($|\set{Y}| = 1$).
To select... 


Measures of significance and interestingness are used to rank rules.

\begin{equation*}
\mathrm{support}(X \rightarrow Y) = \mathrm{support}(X \cup Y) = 
\mathrm{Freq}(X \cup Y) / U > s
\end{equation*}
\begin{equation*}
\mathrm{confidence}(X \rightarrow Y) = \mathrm{support}(X \cup Y) / \mathrm{support}(X) = \hat{P}(Y|X) > c 
\end{equation*}

{\bf Length constraint:}
\begin{equation*}
|X \cup Y|\leq l
\end{equation*}

\begin{enumerate}
\item Dependency model: All rules of form $X \rightarrow Y$ 
with minimum support
$s$, minimum confidence $c$ and satisfying the length constraint $l$.
\item Find all maching rules $X \rightarrow Y$ for which $X \subseteq u_a$.
\item Recommend $N$ unique right-hand-sides ($Y$) of the maching rules 
with the highest confidence.
\end{enumerate}

{\bf Properties:}
\begin{itemize}
\item Model grows in the worst case exponentially with the 
number of items. Model size can be controlled by $l$, $s$ and $c$.
\item Model is very similar to
item-based CF with conditional probability-based similarity (with higher order effects). 
basher et al [Mobasher et al. 2000] presented an algorithm for recommending
%additional webpages to be visited by a user based on association rules. In this
%approach, the historical information about users and their web-access patterns
%were mined using a frequent itemset discovery algorithm and were used to
%generate a set of high con- fidence association rules. The recommendations were
%computed as the union of the consequent of the rules that were supported by the
%pages visited by the user. Lin et al [Lin et al. 2000] used a similar approach
%but they developed an algorithm that is guaranteed to find association rules
%for all the items in the database. Finally, within the context of using
%association rules to derive top-N recommendations, Demiriz [Demiriz 2001]
%studied the problem of how to weight the different rules that are supported
%by the active user. He presented a method that computes the similarity
%between a rule and the active user¿s basket as the product of the confi-
%dence of the rule and the Euclidean distance between items in the
%antecedent of the association rule and the items in the user¿s basket. He
%compared this approach both with the item-based scheme described in Section
%4 (based on our preliminary work presented in [Karypis 2001]) and the
%dependency network-based algorithm [Hecker- man et al. 2000].


\end{itemize}






\section{Recommenderlab Infrastructure}
\section{Examples}
\subsection{A first session}

For this example we use the data set \emph{MSWeb} which is included in
\pkg{recommenderlab}. 
The data set contains anonymous web data from \url{www.microsoft.com} 
for 38,000 anonymous, randomly-selected users. For each
user, the data lists all the areas of the web site (Vroots) that user visited
in a one week time frame {\small\citep{Breese:1998}}.

{\bf Used data:}\\
$4151$ users with $>5$ items and $285$ items. \\
Avg. items per profile:~$8.16$
\marginpar{introduce data}

<<>>=
library("recommenderlab")
data(MSWeb)

MSWeb5 <- MSWeb[rowCounts(MSWeb) >5,]
MSWeb5

LIST(MSWeb5[1:2])
@

<<fig=TRUE>>=
hist(colCounts(MSWeb5), breaks=100)
@

<<fig=TRUE>>=
hist(rowCounts(MSWeb5), breaks=20)
@

The data is stored in sparse format (object of \class{itemMatrix}
defined in package \pkg{arules} which holds a sparse item incidence matrix).

A recommender is created using \func{recommender}.
Here we create a simple recommender which generates recommendations 
solely on the popularity of items (the number of users who have the item in
their profile).

<<>>=
r <- Recommender(MSWeb5, method = "POPULAR")
r

str(getModel(r))
@

The model can be obtained from a recommender using \func{recommender\_model}.
In this case the model is just an vector containing the order of items
according to popularity in the data set and a short description.

Recommendations are generated by \func{predict} in the same way \func{predict}
is used in \proglang{R} for other types of models. The result 
are recommendations in sparse format represented as an \class{itemMatrix}.
\func{inspect} (defined in \pkg{arules}) can be used to
print the recommended items.

<<>>=
recom <- predict(r, MSWeb5[1:2], n=5)
recom

LIST(recom)

bestN(recom, n = 3)
@

\subsection{Evaluation}

\pkg{recommenderlab} provides different evaluation methods. The evaluation
method is determined by choosing an evaluation scheme. Here we create
a $4$-fold cross-valiadation scheme with 3 items given.
\marginpar{explain more.}

<<>>=
scheme <- evaluationScheme(MSWeb5, method="cross", k=4, given=3)
scheme
@

<<>>=
results <- evaluate(scheme, method="POPULAR", n=c(1,5,10,20))
results

avg(results)
@

<<fig=TRUE>>=
plot(results)
@

<<fig=TRUE>>=
plot(results, "prec/rec")
@

\subsection{Comparing different methods}


<<echo=FALSE>>=
load("xresults.rda")
@

<<eval=FALSE>>=
## this needs to be saved to disk! see run_recommender.R
algorithms <- list(
        RANDOM = list(name="RANDOM", param=NULL),
        POPULAR = list(name="POPULAR", param=NULL),
        UBCF = list(name="UBCF", param=list(method="cosine", nn=50)),
        IBCF = list(name="IBCF", param=list(k=30)),
        AR = list(name="AR", param=list(supp=0.05, conf=0.5, maxlen=2))
        )

## run algorithms
results <- evaluate(scheme, algorithms, n=c(1,5,10,20))


## save(results, file="xresults.rda")
@

<<fig=TRUE>>=
plot(results)
@

<<fig=TRUE>>=
plot(results, "prec/rec")
@

\marginpar{getting data in missing!}

\subsection{Compare rankings}

Top-$N$ recommendation lists can be considered rankings
	and can be 
represented as $N$-ary order relations ($\leq$) 
	on the set of all items in the lists (items which do not occur in all lists 
			are added to the end of the corresponding order).

{\bf Average distance between methods:}
E.g., the cardinality of the symmetric difference of two relations (the
		number of tuples contained in exactly one of two relations) 
{\small\citep{Hornik:2008}}

Total number of tuples in relations: 8649 (for 93 items)

	\begin{verbatim}
	UB   IB   AR Pop N
	UB       0 2555 2634  3317
	IB    2555    0 1611  2052
	AR    2634 1611    0  2636
	Pop N 3317 2052 2636     0
	\end{verbatim}

\small
\begin{verbatim}
u_a = {Toy Story (1995), Air Force One (1997), 
	Cop Land (1997), Michael (1996), Blade Runner (1982)}

	UB IB AR Top N Consensus*
	Contact (1997)                 1  4 25     4         4
	Liar Liar (1997)               2 18 32    10         8
	Conspiracy Theory (1997)       3 NA NA    NA        NA
	Star Wars (1977)               4  1  1     1         1
	Return of the Jedi (1983)      5  2  4     2         2
	English Patient, The (1996)    6 26 41     6        12
	Saint, The (1997)              7 NA NA    NA        NA
	Fargo (1996)                   8  3 13     3         3
	Mr. Holland's Opus (1995)      9 34 30    39        17
	Scream (1996)                 10 20 35     7        10
	\end{verbatim}

	* Consensus method: Condorcet (minimizes the weighted sum 
			of symmetric difference distance)




\subsection{ROCR interface}

\subsection{Implementing a new recommender algorithm}

\section{Conclusion}

{\bf Challenges with CF and binary data:}
\begin{itemize}
\item Sparsity of data has an adverse effect on similarity calculation/neighborhood formation.
\item The meaning of $0$ in the data can be either of ``unknown'' or
``dislike''.
Measures like the Jaccard index focus on $1$s.
\item Quality of recommendations is extremely data set dependent.
\end{itemize}


{\bf Bias of evaluation method:}
\begin{itemize}
\item Complete set of ``liked'' items is unknown. Measured precision
is only a lower bound to real precision.
\end{itemize}

\begin{itemize}
\item Many companies face heterogeneous data sources which can best be
aggregated into binary data. 
\item There is only limited research on CF recommender systems using 
binary data 
(except {\small\citep{Breese:1998,Mild:2001,Mild:2003, Demiriz:2004}})
available. More research is needed.
\end{itemize}

{\bf Future research}
\begin{itemize}
\item Provide an open source research toolbox for
recommendations based on binary data with the R code used here. 
\item Model ``dislike'' in binary data {\small\citep{Mobasher:2001}}.
%\item Account for fast changing products 
%    (e.g., vintages differ often significantly and change every year).
\item Investigate recommender engines based on consensus rankings.
\end{itemize}






%
%\bibliographystyle{abbrvnat}
%\bibliography{recommenderlab}
%

\bibliographystyle{abbrvnat}
\bibliography{recommender,recom_talk,data,stuff}

\end{document}

